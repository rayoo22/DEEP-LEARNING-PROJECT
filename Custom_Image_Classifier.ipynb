{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a deep learning custom based image multi-class classifier\n",
    "# It will utilize the MNIST dataset to learn how to classier different images\n",
    "# The aim is to come up with a custom based neural network capable of classifying\n",
    "# images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will utilize the Keras library to build the neural network.\n",
    "# First, we import keras libraries and other packages necessary to build the project.\n",
    "import keras\n",
    "import cv2\n",
    "import imghdr\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will approach this using a Convolution Neural Network\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we download the dataset and load it to a dataframe\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "#load the data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#then reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# to read an image using opencv\u001b[39;00m\n\u001b[0;32m      2\u001b[0m image_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mx_data\u001b[49m[image_index]\n\u001b[0;32m      4\u001b[0m label \u001b[38;5;241m=\u001b[39m y_data[image_index]\n\u001b[0;32m      6\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "# to read an image using opencv\n",
    "image_index = 0\n",
    "image = x_data[image_index]\n",
    "label = y_data[image_index]\n",
    "\n",
    "cv2.imshow(f'Label: {label}', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_data)):\n",
    "    '''\n",
    "    plt.imshow(x_data[i], cmap='gray')\n",
    "    plt.title(f'Label: {y_data[i]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    '''\n",
    "print(y_data)\n",
    "\n",
    "for image_class in os.listdir(data_dir): \n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Normalization will be done to be able to make calssification easier\n",
    "# by that, we will able to compare predictors and targets easily using 0 or 1\n",
    "# this generalizes classification as the deep learning model will be able to pick 0 or 1 values\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# we also convert the target variables into binary values for comparison and error evaluation\n",
    "# to be done and understood well.\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will be using two layers of Convolution and poooling layers in the CNN\n",
    "# I will also incorporate a functin inorder to call the network\n",
    "\n",
    "def custom_image_classifier():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(8, (2, 2), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "300/300 - 6s - 20ms/step - accuracy: 0.8865 - loss: 0.4240 - val_accuracy: 0.9636 - val_loss: 0.1179\n",
      "Epoch 2/20\n",
      "300/300 - 5s - 17ms/step - accuracy: 0.9694 - loss: 0.1052 - val_accuracy: 0.9760 - val_loss: 0.0775\n",
      "Epoch 3/20\n",
      "300/300 - 4s - 14ms/step - accuracy: 0.9768 - loss: 0.0784 - val_accuracy: 0.9804 - val_loss: 0.0639\n",
      "Epoch 4/20\n",
      "300/300 - 4s - 14ms/step - accuracy: 0.9805 - loss: 0.0658 - val_accuracy: 0.9832 - val_loss: 0.0560\n",
      "Epoch 5/20\n",
      "300/300 - 5s - 17ms/step - accuracy: 0.9826 - loss: 0.0585 - val_accuracy: 0.9826 - val_loss: 0.0566\n",
      "Epoch 6/20\n",
      "300/300 - 5s - 18ms/step - accuracy: 0.9848 - loss: 0.0513 - val_accuracy: 0.9850 - val_loss: 0.0497\n",
      "Epoch 7/20\n",
      "300/300 - 5s - 16ms/step - accuracy: 0.9860 - loss: 0.0471 - val_accuracy: 0.9861 - val_loss: 0.0439\n",
      "Epoch 8/20\n",
      "300/300 - 4s - 13ms/step - accuracy: 0.9868 - loss: 0.0423 - val_accuracy: 0.9839 - val_loss: 0.0480\n",
      "Epoch 9/20\n",
      "300/300 - 5s - 18ms/step - accuracy: 0.9879 - loss: 0.0395 - val_accuracy: 0.9872 - val_loss: 0.0374\n",
      "Epoch 10/20\n",
      "300/300 - 5s - 16ms/step - accuracy: 0.9890 - loss: 0.0363 - val_accuracy: 0.9868 - val_loss: 0.0442\n",
      "Epoch 11/20\n",
      "300/300 - 5s - 15ms/step - accuracy: 0.9898 - loss: 0.0331 - val_accuracy: 0.9867 - val_loss: 0.0413\n",
      "Epoch 12/20\n",
      "300/300 - 5s - 15ms/step - accuracy: 0.9908 - loss: 0.0307 - val_accuracy: 0.9883 - val_loss: 0.0394\n",
      "Epoch 13/20\n",
      "300/300 - 5s - 16ms/step - accuracy: 0.9916 - loss: 0.0272 - val_accuracy: 0.9883 - val_loss: 0.0397\n",
      "Epoch 14/20\n",
      "300/300 - 5s - 17ms/step - accuracy: 0.9919 - loss: 0.0260 - val_accuracy: 0.9894 - val_loss: 0.0314\n",
      "Epoch 15/20\n",
      "300/300 - 5s - 17ms/step - accuracy: 0.9929 - loss: 0.0232 - val_accuracy: 0.9885 - val_loss: 0.0386\n",
      "Epoch 16/20\n",
      "300/300 - 5s - 17ms/step - accuracy: 0.9935 - loss: 0.0209 - val_accuracy: 0.9882 - val_loss: 0.0358\n",
      "Epoch 17/20\n",
      "300/300 - 5s - 17ms/step - accuracy: 0.9936 - loss: 0.0200 - val_accuracy: 0.9880 - val_loss: 0.0331\n",
      "Epoch 18/20\n",
      "300/300 - 5s - 18ms/step - accuracy: 0.9939 - loss: 0.0191 - val_accuracy: 0.9896 - val_loss: 0.0341\n",
      "Epoch 19/20\n",
      "300/300 - 5s - 16ms/step - accuracy: 0.9944 - loss: 0.0176 - val_accuracy: 0.9891 - val_loss: 0.0386\n",
      "Epoch 20/20\n",
      "300/300 - 4s - 13ms/step - accuracy: 0.9948 - loss: 0.0165 - val_accuracy: 0.9885 - val_loss: 0.0416\n",
      "Accuracy: 0.9884999990463257 \n",
      " Error: 1.1500000953674316\n"
     ]
    }
   ],
   "source": [
    "# I'll then build a model\n",
    "model = custom_image_classifier()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=2)\n",
    "\n",
    "#I'll then evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
